# A-two-layer-neural-network-classifier
神经网络与深度学习课程作业1：一个进行手写数字识别的两层神经网络分类器
### 简介

这是一个使用NumPy构建的简单两层神经网络分类器，用于分类MNIST数据集。

这里分为三部分：训练、参数查找和测试。
1. 训练
   - 首先定义了sigmoid函数和softmax函数用做激活函数，并且计算了激活函数的梯度。然后利用L2正则化定义了loss函数
   - 利用反向传播算法计算梯度，进行了具体推导和代码实现
   - 学习率下降策略使用指数衰减：每经过epochs个epoch后学习率乘以一个衰减率decay_rate，通过实际训练最后确定epochs=100，decay_rate=0.9可以得到较好的效果
   - 具体实现模型训练，其中采用SGD优化器，随机选取batch_size个样本计算梯度，更新参数。
   - 保存模型参数到文件“params.npz”
2. 超参数查找：
   - 通过网格搜索，大致搜寻合适的学习率、隐藏层大小、正则化强度和batch_size
   - 学习率设置[0,001,0.01,0.1]
   - 隐藏层设置[50,100,200]
   - 正则化强度设置[0.0001,0.001,0.01]
   - batch_sizes设置[64,128,256]
   - 由于SGD优化存在一定随机性，所以每次训练过程采用五折交叉验证，四份当训练集，一份当测试集，取五次准确率的平均值作为对应参数所相应的准确率
   - 最后基于寻找到的合适超参数，根据发现规律进行微调，得到一个最佳的参数结果，并进行训练，得到模型并存储，绘制loss和accuracy曲线，并可视化每层网络参数
3. 测试：
   导入模型，用经过参数查找后的模型进行测试，输出分类精度
   
homewrok_network2.ipynb：包含完整构建过程，包含代码以及输出结果
hyperparameter_selection.json：包含模型利用网格搜索时的输出结果
